{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN-LSTM-code-not-working.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+92UmPPOXx5nkkicDrnEj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"WJlEU5OLkCXh","executionInfo":{"status":"ok","timestamp":1602493397980,"user_tz":-120,"elapsed":751,"user":{"displayName":"Jan Rotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVs9wW38w9pS-o9HKCcQDzL-KnonyETG1JRz3Y=s64","userId":"00819609508745195261"}}},"source":["from numpy import mean\n","from numpy import std\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import TimeDistributed\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.utils import to_categorical\n","from matplotlib import pyplot\n","import os"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"v--DV8TH_1hI"},"source":["%pip install --upgrade wandb\n","import wandb\n","from wandb.keras import WandbCallback\n","wandb.init(project=\"cnn-lstm\")\n","wandb.login()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qoqESWDwmIRQ"},"source":["The Implementation below was done on accelerometer data similar to smartphone data <br>\n","<a href=\"https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition\"> The original GitHub post </a> \n","\n","https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/"]},{"cell_type":"code","metadata":{"id":"hVkmb4DqkJZG","executionInfo":{"status":"ok","timestamp":1602492774654,"user_tz":-120,"elapsed":7545,"user":{"displayName":"Jan Rotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVs9wW38w9pS-o9HKCcQDzL-KnonyETG1JRz3Y=s64","userId":"00819609508745195261"}}},"source":["from keras.datasets import mnist"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"L_RoYwDskCWM","executionInfo":{"status":"ok","timestamp":1602492774655,"user_tz":-120,"elapsed":7537,"user":{"displayName":"Jan Rotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVs9wW38w9pS-o9HKCcQDzL-KnonyETG1JRz3Y=s64","userId":"00819609508745195261"}}},"source":["def reshape_group(data, labels, seq_length = 8):\n","\tfor i in np.unique(labels):\n","\t\tindex = np.where(labels == i)[0]\n","\t\tlabeled_data = data[index]\n","\t\trows = (labeled_data.shape[0]//seq_length) * seq_length\n","\t\tlabeled_data = labeled_data[:rows,:]\n","\t\tlabeled_data = labeled_data.reshape((-1,seq_length,labeled_data.shape[1],labeled_data.shape[2],1))\n","\t\tNewLabels = np.full((labeled_data.shape[0],),fill_value = i)\n","\t\ttry:\n","\t\t\tReshapedData = np.concatenate((ReshapedData,labeled_data),axis=0)\n","\t\t\tReshapedLabel = np.concatenate((ReshapedLabel, NewLabels),axis=0)\n","\t\texcept NameError:\n","\t\t\tReshapedData = labeled_data\n","\t\t\tReshapedLabel = NewLabels\n","\n","\treturn (ReshapedData, to_categorical(ReshapedLabel))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqJl9rAXjiQQ","executionInfo":{"status":"ok","timestamp":1602495258282,"user_tz":-120,"elapsed":1820018,"user":{"displayName":"Jan Rotti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiVs9wW38w9pS-o9HKCcQDzL-KnonyETG1JRz3Y=s64","userId":"00819609508745195261"}},"outputId":"c1f96d06-9576-454d-dcb7-305e050efdb2","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n","\t# define model\n","\tverbose, epochs, batch_size = 0, 200, 64\n","\t# reshape data into time steps of sub-sequences\n","\tseq_length = 8\n","\ttrainX, trainy = reshape_group(trainX, trainy)\n","\ttestX, testy = reshape_group(testX, testy)\n","\twidth, height , n_outputs = trainX.shape[2], trainX.shape[3], trainy.shape[1]\n","\t# define model\n","\tmodel = Sequential()\n","\tmodel.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,width,height,1)))\n","\tmodel.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu')))\n","\tmodel.add(TimeDistributed(Dropout(0.5)))\n","\tmodel.add(TimeDistributed(MaxPooling2D(pool_size=2)))\n","\tmodel.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu')))\n","\tmodel.add(TimeDistributed(Conv2D(filters=64, kernel_size=3, activation='relu')))\n","\tmodel.add(TimeDistributed(Dropout(0.5))) \n","\tmodel.add(TimeDistributed(MaxPooling2D(pool_size=2)))\n","\tmodel.add(TimeDistributed(Flatten()))\n","\tmodel.add(LSTM(100))\n","\tmodel.add(Dropout(0.5))\n","\tmodel.add(Dense(100, activation='relu'))\n","\tmodel.add(Dense(n_outputs, activation='softmax'))\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\t# fit network\n","\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose, shuffle =True,callbacks=[WandbCallback()])\n","\tmodel.save(os.path.join(wandb.run.dir, \"model.h5\"))\n","\t# evaluate model\n","\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n","\treturn accuracy\n"," \n","# summarize scores\n","def summarize_results(scores):\n","\tprint(scores)\n","\tm, s = mean(scores), std(scores)\n","\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n"," \n","# run an experiment\n","def run_experiment(repeats=1):\n","\t# load data\n","\t# trainX, trainy, testX, testy = load_dataset()\n","\t(trainX,trainy),(testX,testy) = mnist.load_data()\n","\t# repeat experiment\n","\tscores = list()\n","\tfor r in range(repeats):\n","\t\tscore = evaluate_model(trainX, trainy, testX, testy)\n","\t\tscore = score * 100.0\n","\t\tprint('>#%d: %.3f' % (r+1, score))\n","\t\tscores.append(score)\n","\t# summarize results\n","\tsummarize_results(scores)\n"," \n","# run the experiment\n","run_experiment()"],"execution_count":7,"outputs":[{"output_type":"stream","text":[">#1: 45.703\n","[45.70281207561493]\n","Accuracy: 45.703% (+/-0.000)\n"],"name":"stdout"}]}]}